{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UBathy\n",
    "\n",
    "`UBathy` is an open source software written in Python for nearshore bathymetry estimation from videos of calibrated images or of geo-referenced planviews. \n",
    "\n",
    "### Description\n",
    "The algorithm for bathymetry estimation is based on extracting wave modes from videos of nearshore surface wave propagation. These videos can be formed either from camera images, which must have been previously calibrated, or from geo-referenced planviews. For each wave mode extracted from the videos, the frequency and the spatially dependent wavenumbers are obtained. The frequencies and wavenumbers from different videos are used to estimate the bathymetry by adjusting the dispersion relation for linear surface waves. Bathymetries estimated at different times are finally aggregated using a Kalman filter to obtain the final bathymetries. The development of this software is suitable for Argus-type video monitoring stations and from moving cameras such as those acquired from drones. The calibration of these videos and the generation of planviews, which are necessary in the case of drones, can be done using the software in [UCalib](https://github.com/Ulises-ICM-UPC/UCalib) and [UDrone](https://github.com/Ulises-ICM-UPC/UDrone). Details on the algorithm and methodology are described in\n",
    "> *Simarro, G.; Calvete, D.; Nosequienmas. UBathy+: y alagoque lo describa?. To be submited.*\n",
    "\n",
    "The bathimetry estimation process consists of the following steps:\n",
    "\n",
    " 1. [Video setup](#video-setup)\n",
    " 2. [Generation of meshes](#generation-of-meshes)\n",
    " 3. [Mode decomposition](#mode-decomposition)\n",
    " 4. [Wavenumber computation](#wavenumber-computation)\n",
    " 5. [Bathymetry estimation](#bathymetry-estimation)\n",
    " \n",
    "Finally, `UBathy` allows to aggregate bathymetries obtained at different times using a Kalman filter:\n",
    "\n",
    " 6. [Kalman estimation](#kalman-estimation)\n",
    "\n",
    "\n",
    "### Requirements and project structure\n",
    "To run the software it is necessary to have Python3 (3.8) and install the following dependencies:\n",
    "- cv2 (4.2.0)\n",
    "- numpy (1.19.5)\n",
    "- scipy (1.3.3)\n",
    "\n",
    "In parenthesis we indicate the version with which the software has been tested. It is possible that it works with older versions. \n",
    "\n",
    "The structure of the project is the following:\n",
    "* `example.py`\n",
    "* `example_notebook.py`\n",
    "* **`ubathy`**\n",
    "  * `ubathy.py`\n",
    "  * `ulises_ubathy.py`\n",
    "* **`example`**\n",
    "  * **`videos`**\n",
    "    * `videoFilename01.mp4` (or .avi)\n",
    "    * **`videoFilename01`**\n",
    "      * `videoFilename01_000000000000.png` (or .jpg)\n",
    "      * . . .\n",
    "    * . . .\n",
    "  * **`data`**\n",
    "    * `xy_boundary.txt`\n",
    "    * `parameters.json`\n",
    "    * `videos4dates.json`\n",
    "    * `parametersKalman.json`\n",
    "    * **`videoFilename01`**\n",
    "      * `<anyname>cal.txt`\n",
    "      * `<anyname>zs.txt`\n",
    "      * or\n",
    "      * `<anyname>crxyz.txt`\n",
    "    * . . .\n",
    "  * **`scratch`**\n",
    "    * `mesh_Zb.npz`\n",
    "    * **`videoFilename01`**\n",
    "      * `mesh_M.npz`\n",
    "      * `mesh_K.npz`\n",
    "      * **`M_modes`**\n",
    "        * `t<timeInVideo>_w<windowTime>_T<period>_<modeType>.npz`\n",
    "        * . . . \n",
    "      * **`K_wavenumber`**\n",
    "        * `t<timeInVideo>_w<windowTime>_T<period>_<modeType>_K.npz`\n",
    "        * . . . \n",
    "    * . . .\n",
    "    * **`Zb_bathymetries`**\n",
    "      * `date01_<modeType>_Zb.npz`\n",
    "      * . . .\n",
    "    * **`plots`**\n",
    "      * `mesh_Zb.png`\n",
    "      * **`videoFilename01`**\n",
    "        * `mesh_M.png`\n",
    "        * `mesh_M_inImage.png`\n",
    "        * `mesh_K.png`\n",
    "        * `mesh_K_inImage.png`\n",
    "        * **`M_modes`**\n",
    "          * `t<timeInVideo>_w<windowTime>_T<period>_<modeType>.png`\n",
    "          * . . . \n",
    "        * **`K_wavenumber`**\n",
    "          * `t<timeInVideo>_w<windowTime>_T<period>_<modeType>_K.png`\n",
    "          * . . .\n",
    "      * . . .\n",
    "      * **`Zb_bathymetries`**\n",
    "        * `date01_<modeType>_Zb.png`\n",
    "        * . . .\n",
    "  * **`bathymetries`**\n",
    "    * `mesh_Zb.txt`\n",
    "    * `date1_Zb.txt`\n",
    "    * `date1_Zb_kalman.txt`\n",
    "    * . . .\n",
    "    * **`plots`**\n",
    "      * `mesh_zb.png`\n",
    "      * `date1_zb.png`\n",
    "      * `date1_zb_kalman.png`\n",
    "      * . . .\n",
    "\n",
    "\n",
    "The local modules of `UBathy` are located in the **`ubathy`** folder.\n",
    "\n",
    "To run a demo in folder **`example`** experienced users can run the `example.py` file in a terminal.\n",
    "\n",
    "Atlernatively we provide the file `example_notebook.ipynb` to be used in a Jupyter Notebook. In that case, import modules and set the main path of the example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, 'ubathy')\n",
    "import ubathy as ubathy\n",
    "pathFolderMain = 'example_00'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set also the folders where the videos (**`videos`**) and data files (**`data`**) are located, and the folders where the temporary data (**`scratch`**) and the estimated bathymetries (**`bathymetries`**) will be stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathFolderData = os.path.join(pathFolderMain, 'data')\n",
    "pathFolderVideos = os.path.join(pathFolderMain, 'videos')\n",
    "pathFolderScratch = os.path.join(pathFolderMain, 'scratch')\n",
    "pathFolderBathymetries = os.path.join(pathFolderMain, 'bathymetries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video setup\n",
    "The bathymetric extraction algorithm is applied to videos stored in the **`videos`** folder. For each video `<videoFilename>` a folder with the same name contains the frames with the format `<videoFilename>_<milliseconds>.png` (or `.jpg`). Depending on whether the frames come from calibrated camera images or from geo-referenced planviews, different files have to be provided.\n",
    "\n",
    "#### Calibrated camera images\n",
    "A calibration file `<anyname>cal.txt` of the camera must exist in the folder **`data/<videoFilename>`** with the following parameters:\n",
    "\n",
    "| Magnitudes | Variables | Units |\n",
    "|:--|:--:|:--:|\n",
    "| Camera position coordinates | `xc`, `yc`, `zc` | _m_ |\n",
    "| Camera orientation angles | `ph`, `sg`, `ta` | _rad_ |\n",
    "| Lens radial distortion (parabolic, quartic) | `k1a`, `k2a` | _-_ |\n",
    "| Lens tangential distortion (parabolic, quartic) | `p1a`, `p2a` | _-_ |\n",
    "| Pixel size | `sc`, `sr` | _-_ |\n",
    "| Decentering | `oc`, `rr` | _pixel_ |\n",
    "| Image size | `nc`, `nr` | _pixel_ |\n",
    "| Calibration error | `errorT`| _pixel_ |\n",
    "\n",
    "This file can be obtained using the [UBasic](https://github.com/Ulises-ICM-UPC/UBasic) software. In the same directory should also exist the file `<anyname>zs.txt` with the position of the water surface during the recording of the video with the following structure:\n",
    "* `<anyname>zs.txt`: One line with\n",
    ">`z-coordinate-free-surface`\n",
    "\n",
    "The coordinates of the camera position `(xc, yc, zc, ph, sg, ta)` and the position of the water surface `(zs)` are referenced to the same coordinate system in which the bathymetries are to be obtained.\n",
    "\n",
    "#### Geo-referenced planviews\n",
    "If the frames correspond to planviews, in the folder **`data/<videoFilename>`** there must exists the file `<anyname>_crxyz.txt` with the correspondence between the pixels of the planview and the coordinate system in which the bathymetry is going to be obtained. The structure of this file is the following:\n",
    "* `<anyname>_crxyz.txt`: One line for each pixel\n",
    ">`pixel-column`, `pixel-row`, `x-coordinate`, `y-coordinate`, `z-coordinate-free-surface`\n",
    "\n",
    "On previous files, quantities must be separated by at least one blank space between them and the last record should not be continued with a newline (return).\n",
    "\n",
    "### Run video extraction\n",
    "If the video has been stored in `MP4` (recommended) and `AVI` image format, the frames must be extracted before processing. Set a list of the videos to be processed with the name of each `<videoFilename>`. In case you want to extract all the videos that are in **`videos`** provide an empty list (i.e. `[]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfVideos = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the extraction rate of the frames:\n",
    "\n",
    "|  | Parameter | Suggested value | Units |\n",
    "|:--|:--:|:--:|:--:|\n",
    "| Extraction framerate | `FPS` | _2.0_ | _1/s_ |\n",
    "Set FPS=0 to extract all frames from the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case that for a `<videoFilename>` has already been extracted, set `overwrite = True` to extract it again and to `False` otherwise. Run the code to extract frames from de videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame extraction of video 20200801083000 from 20200801083000.mp4 at 1.88 fps\n",
      "... frame extraction of video 20200801084500 from 20200801084500.mp4 at 1.88 fps\n"
     ]
    }
   ],
   "source": [
    "overwrite = False\n",
    "#\n",
    "ubathy.Video2Frames(pathFolderVideos, listOfVideos, FPS, overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, for each `<videoFilename>` a folder **`videos/<videoFilename>`** containing the frames with the format `<videoFilename>_<milliseconds>.png` is generated.\n",
    "\n",
    "## Generation of meshes\n",
    "In general, the meshes for the extraction of wave modes, the calculation of wavenumbers and bathymetries are performed on the basis of a regular mesh of equilateral triangles in an x-y plane domain. The mesh for the extraction of the modes is adjusted according to the position of the pixels of the images of each video `<videoFilename>` if the frames come from calibrted camera images. For geo-referenced planviews, the mesh extraction of wave modes corresponds to spatial coordinates of the pixels specified in the file `<anyname>_crxyz.txt`.\n",
    "\n",
    "To generate these meshes it is necessary to provide in the folder **`data`** a file `xy_boundary.txt` with the coordinates of the polygon vertices of the region in which the bathymetry is going to be extracted and to set in the file `parameters.json` the spacing between the nodes of the different meshes.\n",
    "\n",
    "The structure of each of these files is the following:\n",
    "* `xy_boundary.txt`: For each vertex point one line with (minimum 3)\n",
    ">`x-coordinate`, `y-coordinate`\n",
    "\n",
    "Quantities must be separated by at least one blank space between. These points are to be given in the same coordinate system in which the bathymetry is going to be obtained\n",
    "* `parameters.json`: Set the values of node distance for ech mesh\n",
    "\n",
    "| Object-name | Description | Suggested value | Units | \n",
    "|:--|:--:|:--:|:--:|\n",
    "| `delta_M` | mode-node distance | 2.5 | _m_ |\n",
    "| `delta_K` | wavenumber-node distance | 5.0 | _m_ |\n",
    "| `delta_Zb` | bathymetry-node distance | 10.0| _m_ |\n",
    "\n",
    "\n",
    "### Run meshes generation\n",
    "To verify the arrangement of the mesh, images of the meshes and the position of the grid nodes relative to the video frames can be generated. Set parameter `verbosePlot = True`, and to `False` otherwise. In the case that the meshes have already been generated, set `overwrite = True` to generate them again and to `False` otherwise. Set the values of these control parameters and run the code to generate the meshes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... mesh_Zb was already created\n",
      "... mesh_M for video 20200801083000 was already created\n",
      "... mesh_K for video 20200801083000 was already created\n",
      "... creating mesh_M for video 20200801084500\n",
      "... creating mesh_K for video 20200801084500\n"
     ]
    }
   ],
   "source": [
    "overwrite = False\n",
    "verbosePlot = True\n",
    "#\n",
    "ubathy.CreateMeshes(pathFolderData, pathFolderVideos, pathFolderScratch, listOfVideos, overwrite, verbosePlot)\n",
    "pathFolderData = os.path.join(pathFolderMain, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, in the scratch folder **`scratch`**, the file containing the mesh for the bathymetry `mesh_Zb.npz`, which is common for all the videos, and the meshes for obtaining the wave modes `mesh_M.npz` and the wavenumbers `mesh_K.npz` for each video `<videoFilename>` will be obtained. In case the plots have been generated, the corresponding figures will be found in the **`scratch/plots`** folder, following the same folder structure as the data files. \n",
    "\n",
    "## Mode decomposition\n",
    "Once the frames of the videos are available and the meshes have been generated, the decomposition of the waves into modes can be performed. Prior to the decomposition into modes, an algorithm based on principal component analysis (Robust PCA) can be applied to reduce the noise in the images. The code includes two algorithms for the decomposition of the waves into modes. One is based on singular value decomposition (EOF) and the other on a dimensionality reduction algorithm (DMD). These analyses are performed on sub-videos of the main video. The length of these sub-videos and their number will determine the wave periods that can be solved and the number of modes.\n",
    "The following parameters need to be set in the `parameters.json` file: \n",
    "\n",
    "| Object-name | Description | Default value | Suggested range | Units | \n",
    "|:--|:--:|:--:|:--:|:--:|\n",
    "| `candes_iter` | iterations robust algorithm | 50 | 0-100 | _-_ |\n",
    "| `DMD_or_EOF` | type of mode decomposition  | DMD | DMD or EOF |  |\n",
    "| `DMD_rank` | number of DMD modes | 6 | 4-10 | _-_ |\n",
    "| `EOF_variance` | minimun variance of the EOF modes | 0.025 | 0.015-0.030 | _-_ |\n",
    "| `time_step` | time steps for video analysis | 30.0 | 1.0-60 | _s_ |\n",
    "| `time_windows` | temporal windows length | [60.0, 90.0, 120.0] | 30-150 | _s_ |\n",
    "| `min_period` | minimum wave period  | 3 | site-dependent  | _s_ |\n",
    "| `max_period` | maximum wave period | 15 | site-dependent | _s_ |\n",
    "\n",
    "\n",
    "### Run mode decomposition\n",
    "Set the values of the plot generation and overwrite parameters, and run the wave mode decomposition code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading video 20200801083000\n"
     ]
    }
   ],
   "source": [
    "overwrite = False\n",
    "verbosePlot = True\n",
    "#\n",
    "ubathy.ObtainWAndModes(pathFolderData, pathFolderVideos, pathFolderScratch, listOfVideos, overwrite, verbosePlot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, for all the videos included in the list `listOfVideos` and for every time window, the wave modes that verify the conditions set in the `parameters.json` file will be obtained. Each of these wave modes has an associated wave period. For each mode, a `t<timeInVideo>_w<windowTime>_T<period>_<modeType>.npz` file will be created in the **`scratch/<videoFilename>/M_modes`** folder containing, among other quantities, the phase of the waves at the nodes of the `mesh_M.npz`. In case the plots have been generated, the corresponding figures with the phase and amplitude of the modes will be found in the **`scratch/plots`** folder, following the same folder structure as the data files. \n",
    "\n",
    "## Wavenumber computation\n",
    "The spatial structure of the modes is analysed to extract the wavenumber corresponding to each spatial point of the mode. The wavenumber is determined at each point from the values of the phase of the mode in its vicinity. The size of the spatial balls for this analysis is determined by the range of depths to be measured and the number of balls to use. The following parameters need to be set in the `parameters.json` file:\n",
    "\n",
    "| Object-name | Description | Default value | Suggested range | Units | \n",
    "|:--|:--:|:--:|:--:|:--:|\n",
    "| `min_depth` | minimum depth of inversion  | 0.5 | 0.25-1.0 | _m_ |\n",
    "| `max_depth` | maximum depth of inversion  | 6.0 | 5.0-10.0 | _m_ |\n",
    "| `nRadius_K` | number of space balls for wavenumber calculation | 2 | 2-5 | _-_ |\n",
    "| `nRANSAC_K` | number of iterations for RANSAC implementation | 50 | 20-100 | _-_ |\n",
    "\n",
    "### Run wavenumber computation\n",
    "Set the values of the plot generation and overwrite parameters, and run the wave wavenumber computation code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "verbosePlot = True\n",
    "#\n",
    "ubathy.ObtainK(pathFolderData, pathFolderScratch, listOfVideos, overwrite, verbosePlot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, for all the modes obteined after analising the videos included in the list `listOfVideos`, the wavenumber will be obtained. For each mode, a `t<timeInVideo>_w<windowTime>_T<period>_<modeType>_K.npz` file will be created in the **`scratch/<videoFilename>/K_modes`** folder containing, among other quantities, the wave period and wavemumber at the nodes of the `mesh_K.npz`. In case the plots have been generated, the corresponding figures with the phase and amplitude of the modes will be found in the **`scratch/plots`** folder, following the same folder structure as the data files. \n",
    "\n",
    "## Bathymetry estimation\n",
    "Finally, once the wave modes have been extracted from the videos, and from these, the period and wave number at points in the space of the different K grids, the bathymetries can be estimated. These bathymetries will be made by composing modes from different videos listed in the file `videos4dates.json` in the folder **`data`**. The fields in this file have the following format:\n",
    "* `videos4dates.json`: For each bathymetry the name of all the `<videoFilename>`'s to compose a `<date>`\n",
    ">  `\"<date1>\"`: [`\"<videoFilename01>\"`, `\"<videoFilename02>\"`, `\"<videoFilename03>\"`, . . .]\n",
    "\n",
    "To compose the bathymetry at a point in space, frequency and wavenumber pairs are used in an environment determined by the wavelength at that point. In the composition of the bathymetry the standard deviation of the _gamma_ parameter of the different modes is used as a quality criterion. The following parameters need to be set in the `parameters.json` file:\n",
    "\n",
    "| Object-name | Description | Default value | Suggested range | Units | \n",
    "|:--|:--:|:--:|:--:|:--:|\n",
    "| `stdGammaC` | critical value for the standart deviation of the _gamma_ parameter | 0.075 | 0.060-0.090 | _-_ |\n",
    "| `coef_R_Zb` | wavelength ratio for the space ball for depth calculation  | 0.2 | 0.10-0.30 | _-_ |\n",
    "\n",
    "### Run bathymetry estimation\n",
    "Set the values of the plot generation and overwrite parameters, and run the bathymetry estimation code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "verbosePlot = True\n",
    "#\n",
    "ubathy.ObtainZb(pathFolderData, pathFolderScratch, pathFolderBathymetries, overwrite, verbosePlot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, for each `<date>` in the file `videos4dates.json`, a bathymetry `<date>_<modeType>_Zb.npz` at the nodes of the `mesh_Zb.npz` will be created in the folder **`scratch/Zb_bathymetries`**. In case the plots have been generated, the corresponding figures with the bathymetry will be found in the **`scratch/plots`** folder, following the same folder structure as the data files.\n",
    "\n",
    "To facilitate the reading and processing of these bathymetries, files containing the grid points and bathymetries in _plain text_ are placed in the folder **`bathymetries`**. The structure of each of these files is the following:\n",
    "* `mesh_Zb.txt`: For each grid points of the mesh one line with\n",
    ">`x-coordinate`, `y-coordinate`\n",
    "\n",
    "* `<date>_Zb.txt`: For each grid points of the mesh one line with\n",
    ">`z-coordinate`, `self_error`\n",
    "\n",
    "The order of the grid points in the mesh and bathymetry files is the same. Therefore, to the same line number belongs the coordinates and the bathymetry of the same point in the corresponding files. The values of the bathymetry at the points where it has not been possible to evaluate are indicated by _`NaN`_ values. In case the plots have been generated, the corresponding figures with the bathymetry will be found in the **`bathymetries/plots`** folder.\n",
    "\n",
    "## Kalman estimation\n",
    "Coming soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Contact us\n",
    "\n",
    "Are you experiencing problems? Do you want to give us a comment? Do you need to get in touch with us? Please contact us!\n",
    "\n",
    "To do so, we ask you to use the [Issues section](https://github.com/Ulises-ICM-UPC/UBathy/issues) instead of emailing us.\n",
    "\n",
    "## Contributions\n",
    "\n",
    "Contributions to this project are welcome. To do a clean pull request, please follow these [guidelines](https://github.com/MarcDiethelm/contributing/blob/master/README.md)\n",
    "\n",
    "## License\n",
    "\n",
    "UCalib is released under a [AGPL-3.0 license](https://github.com/Ulises-ICM-UPC/UBathy/blob/master/LICENSE). If you use UDrone in an academic work, please cite:\n",
    "\n",
    "    @Article{nokey,\n",
    "      AUTHOR = {npzSimarro, Gonzalo and Calvete, Daniel and Nosequienmas},\n",
    "      TITLE = {UBathy+: y alagoque lo describa?},\n",
    "      JOURNAL = {Environmental Modelling & Software},\n",
    "      VOLUME = {},\n",
    "      YEAR = {2022},\n",
    "      NUMBER = {1},\n",
    "      ARTICLE-NUMBER = {},\n",
    "      URL = {},\n",
    "      ISSN = {},\n",
    "      DOI = {},\n",
    "      NOTE = {To be submited}\n",
    "      }\n",
    "\n",
    "    @Online{ulisesbathy, \n",
    "      author = {Simarro, Gonzalo and Calvete, Daniel and Nosequienmas},\n",
    "      title = {UBathy},\n",
    "      year = 2022,\n",
    "      url = {https://github.com/Ulises-ICM-UPC/UBathy}\n",
    "      }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
